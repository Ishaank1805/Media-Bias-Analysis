
# TRAINING CODE MODIFICATION GUIDE

## 1. Update Dataset Class in training_event_relation_graph.py

Add this to custom_dataset.__getitem__():

```python
# Load factual/interpretive labels
import pickle

# Load cached labels (faster than JSON)
if not hasattr(self, 'fact_interp_cache'):
    split_name = 'train' if 'train' in file_path else 'dev'
    with open(f'./fact_interp_labels_{split_name}.pkl', 'rb') as f:
        self.fact_interp_cache = pickle.load(f)

filename = os.path.basename(file_path)
fact_interp_labels = self.fact_interp_cache.get(filename, [])

# Convert to tensor (only for events, filter out -1)
label_fact_interp = []
for i, event_label in enumerate(article_json['event_label']):
    if event_label['event_label'] == 1:  # Is an event
        if i < len(fact_interp_labels) and fact_interp_labels[i] != -1:
            label_fact_interp.append(fact_interp_labels[i])
        else:
            label_fact_interp.append(0)  # Default factual

label_fact_interp = torch.tensor(label_fact_interp)

# Add to return dict
dict["label_fact_interp"] = label_fact_interp
```

## 2. Update Model Architecture

Add to Event_Relation_Graph.__init__():

```python
# Factual/Interpretive classification head
self.fact_interp_head_1 = nn.Linear(768, 384, bias=True)
self.fact_interp_head_2 = nn.Linear(384, 2, bias=True)
```

Add to forward() method:

```python
# Factual/Interpretive classification
fact_interp_scores = self.fact_interp_head_2(
    self.relu(self.fact_interp_head_1(event_embeddings))
)
fact_interp_loss = self.crossentropyloss(fact_interp_scores, label_fact_interp)

# Add to return statement
return (..., fact_interp_loss, fact_interp_scores)
```

## 3. Update Training Loop

Add fact_interp_loss to the backward pass:

```python
fact_interp_weighted_loss.backward(retain_graph=True)
```

## 4. Update Evaluation

Add factual/interpretive evaluation metrics to evaluate() function.
